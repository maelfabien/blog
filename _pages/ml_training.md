---
title: Machine Learning With Python
layout: single
permalink: /ml_training/
author_profile: false
header :
    image: "https://maelfabien.github.io/assets/images/wolf.jpg"
---

## Course 1: Introduction to Machine Learning

[Basics of Machine Learning and Motivation](https://maelfabien.github.io/machinelearning/ml_base/) : A first approach to machine learning. We’ll go over the main motivations, the main kind of algorithms, what they can be used for…

[Metrics in Machine Learning](): Todo

[Why learning works? An overview of Vapnik–Chervonenkis theory](): Todo

[Prepare data for Machine Learning](): Todo

[Overfitting and regularization](): Todo

## Course 2: Supervised Machine Learning

### a. Statistical inference

[Linear Regression (Part 1)](https://maelfabien.github.io/statistics/linreg/): We’ll explore the simple framework of OLS and multi-dimensional regression.

[Linear Regression (Part 2)](https://maelfabien.github.io/statistics/linreg2/): Random design matrix, Normal regression, Pseudo Least Squares and other extensions…

[The Logistic Regression](https://maelfabien.github.io/statistics/linreg3/): One of the fundamentals algorithms for classification.

### b. Core algorithms

[The Bayes Classifier](https://maelfabien.github.io/machinelearning/bayes/): At the core of any algorithm, the Bayes Classifier is considered as one of the first algorithm to master.

[Support Vector Machine](): Todo

[Linear Discriminant Analysis (LDA) and QDA ](https://maelfabien.github.io/machinelearning/LDA/): Intuition behind LDA, when it should be used, and the maths behind it. We’ll also quick cover the Quadratic version of LDA.

[Tree-based methods with CART](): Todo

### c. Bagging Methods

[Random Forest and Extra Trees](): Todo

### d. Boosting Methods

[Adaptative Boosting (AdaBoost)](https://maelfabien.github.io/machinelearning/adaboost/) : A clear approach of boosting algorithms and adaptative boosting with illustrations. When should we use boosting ? What are the foundations of the algorithm ?

[Gradient Boosting (Regression)](https://maelfabien.github.io/machinelearning/GradientBoost/): The basics of gradient boosting regression, and implementation of a high level version in Python.

[Gradient Boosting (Classification)](https://maelfabien.github.io/machinelearning/GradientBoostC/): Gradient boosting classification as an extension of the Regression.

### e. Time Series

[Introduction to Time Series](https://maelfabien.github.io/statistics/TimeSeries1/) : A first approach to exploring a time series in Python with open data.

[Key Concepts in Time Series](https://maelfabien.github.io/statistics/TimeSeries2/) : Stationarity, ergodicity... We'll cover the key concepts of time series.

[Basics of Time Series Forecasting](https://maelfabien.github.io/statistics/TimeSeries3/) : How do we make a series stationary ? How do we forecast ?

[Time Series Forecasting with Facebook Prophet](https://maelfabien.github.io/statistics/TimeSeries4/) : Explore time series forecasting using the Prophet open-source package.

[Handle missing values in Time Series](https://maelfabien.github.io/statistics/TimeSeries5/) : A quick illustration of backward filling and forward filling.

### f. Recommmendation Systems

[Content-based Filtering]() : Todo

[Colaborative Filtering]() : Todo

## Course 3: Optimization and tuning

[GridSearch vs. RandomizedSearch](https://maelfabien.github.io/machinelearning/GridRand/) : When it comes to parameter selection, you usually encounter 2 main solutions. GridSearch and RandomizedSearch. What is the main difference between these 2 techniques ? What are the pros and cons of each technique ?

[Bayesian Hyperparameter Optimisation (HyperOpt)](https://maelfabien.github.io/machinelearning/HyperOpt/) : Bayesian Hyperparameter Optimization is a great alternative to GridSearch and RandomizedSearch. How does it work ? How do you implement it in Python ?

[AutoML with h2o](https://maelfabien.github.io/machinelearning/AutoML/) : The interest in AutoML is rising over time. AutoML algorithms are reaching really good rankings in data science competitions. But what is AutoML ? How does it work ? When to use it ? And how can you implement an AutoML pipeline in Python ?

[Machine Learning Explainability](https://maelfabien.github.io/machinelearning/Explainability/) : We'll cover permutation importance, partial dependence plots and SHAP Values to better explain the outputs of a ML model.

## Course 4: Unsupervised Machine Learning

[Clustering algorithms](): Todo

[Unsupervised Anomaly detection](): Todo

[Reducing dimension](): Todo


All codes and exercises are accessible on this repo. Don't hesitate to show your suppot and star the repo:

<div class="github-card" data-github="maelfabien/Machine_Learning_Tutorials" data-width="100%" data-height="" data-theme="default"></div>
<script src="//cdn.jsdelivr.net/github-cards/latest/widget.js"></script>


<script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/unique-methods/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">window.dojoRequire(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us3.list-manage.com","uuid":"c76a8e2ec2bd989affb9a074f","lid":"4646542adb","uniqueMethods":true}) })</script>
